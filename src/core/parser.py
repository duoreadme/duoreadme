"""
å†…å®¹è§£æå™¨æ¨¡å—

è´Ÿè´£è§£æç”Ÿæˆå“åº”ä¸­çš„å¤šè¯­è¨€READMEå†…å®¹ã€‚
"""

import re
from typing import Dict, List, Optional
from ..models.types import ParsedReadme
from ..utils.json_extractor import extract_json_content
from ..utils.logger import debug, info, warning, error


class Parser:
    """è§£æå™¨ç±»ï¼Œè´Ÿè´£è§£æå¤šè¯­è¨€READMEå†…å®¹"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§£æå™¨"""
        # åªä¿ç•™JSONæ ¼å¼è§£æï¼Œç§»é™¤æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.language_patterns = {}
        
        # ç‰¹æ®Šå¤„ç†æ³°è¯­ï¼ˆAIå¯èƒ½ç”Ÿæˆ"æ³°è¯­ç‰ˆæœ¬readme:"ï¼‰
        self.language_patterns["th"] = []
        
        self.filename_map = {
            "zh": "README.zh.md",
            "zh-Hans": "README.zh.md",
            "zh-Hant": "README.zh-Hant.md",
            "en": "README.md",      # è‹±æ–‡READMEæ”¾åœ¨æ ¹ç›®å½•
            "ja": "README.ja.md",
            "ko": "README.ko.md",
            "fr": "README.fr.md",
            "de": "README.de.md",
            "es": "README.es.md",
            "it": "README.it.md",
            "pt": "README.pt.md",
            "pt-PT": "README.pt-PT.md",
            "ru": "README.ru.md",
            "th": "README.th.md",
            "vi": "README.vi.md",
            "hi": "README.hi.md",
            "ar": "README.ar.md",
            "tr": "README.tr.md",
            "pl": "README.pl.md",
            "nl": "README.nl.md",
            "sv": "README.sv.md",
            "da": "README.da.md",
            "no": "README.no.md",
            "nb": "README.nb.md",
            "fi": "README.fi.md",
            "cs": "README.cs.md",
            "sk": "README.sk.md",
            "hu": "README.hu.md",
            "ro": "README.ro.md",
            "bg": "README.bg.md",
            "hr": "README.hr.md",
            "sl": "README.sl.md",
            "et": "README.et.md",
            "lv": "README.lv.md",
            "lt": "README.lt.md",
            "mt": "README.mt.md",
            "el": "README.el.md",
            "ca": "README.ca.md",
            "eu": "README.eu.md",
            "gl": "README.gl.md",
            "af": "README.af.md",
            "zu": "README.zu.md",
            "xh": "README.xh.md",
            "st": "README.st.md",
            "sw": "README.sw.md",
            "yo": "README.yo.md",
            "ig": "README.ig.md",
            "ha": "README.ha.md",
            "am": "README.am.md",
            "or": "README.or.md",
            "bn": "README.bn.md",
            "gu": "README.gu.md",
            "pa": "README.pa.md",
            "te": "README.te.md",
            "kn": "README.kn.md",
            "ml": "README.ml.md",
            "ta": "README.ta.md",
            "si": "README.si.md",
            "my": "README.my.md",
            "km": "README.km.md",
            "lo": "README.lo.md",
            "ne": "README.ne.md",
            "ur": "README.ur.md",
            "fa": "README.fa.md",
            "ps": "README.ps.md",
            "sd": "README.sd.md",
            "he": "README.he.md",
            "yue": "README.yue.md"
        }
    
    def parse_multilingual_content(self, response_text: str, languages: Optional[List[str]] = None) -> ParsedReadme:
        """
        è§£æå¤šè¯­è¨€READMEå†…å®¹
        
        Args:
            response_text: ç”Ÿæˆå“åº”æ–‡æœ¬ï¼ˆJSONæ ¼å¼ï¼‰
            languages: è¦è§£æçš„è¯­è¨€åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è§£ææ‰€æœ‰æ”¯æŒçš„è¯­è¨€
            
        Returns:
            ParsedReadme: è§£æç»“æœå¯¹è±¡
        """
        if languages is None:
            # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æ”¯æŒçš„è¯­è¨€ä»£ç 
            languages = ["en", "zh-Hans", "zh-Hant", "ja", "ko", "fr", "de", "es", "it", "pt", "pt-PT", "ru", "th", "vi", "hi", "ar", "tr", "pl", "nl", "sv", "da", "no", "nb", "fi", "cs", "sk", "hu", "ro", "bg", "hr", "sl", "et", "lv", "lt", "mt", "el", "ca", "eu", "gl", "af", "zu", "xh", "st", "sw", "yo", "ig", "ha", "am", "or", "bn", "gu", "pa", "te", "kn", "ml", "ta", "si", "my", "km", "lo", "ne", "ur", "fa", "ps", "sd", "he", "yue", "zh-Hant"]
        
        results = {}
        found_languages = []
        
        # ä½¿ç”¨æ–°çš„JSONæå–å™¨
        json_data, language_content = extract_json_content(response_text)
        
        if json_data:
            debug(f"ğŸ” æˆåŠŸæå–JSONæ•°æ®ï¼ŒåŒ…å« {len(json_data)} ä¸ªé”®")
            
            # ä½¿ç”¨æå–çš„è¯­è¨€å†…å®¹
            for lang_code, content in language_content.items():
                if lang_code in languages:
                    results[lang_code] = content
                    found_languages.append(lang_code)
                    debug(f"âœ… æˆåŠŸè§£æ {lang_code} è¯­è¨€å†…å®¹")
            
            if results:
                debug(f"âœ… æˆåŠŸè§£æ {len(results)} ç§è¯­è¨€")
                return ParsedReadme(
                    content=results,
                    languages=found_languages,
                    total_count=len(results)
                )
        else:
            error("âŒ æ— æ³•æå–JSONæ•°æ®")
            debug(f"ğŸ” åŸå§‹å“åº”æ–‡æœ¬: {response_text[:200]}...")
        
        if not results:
            warning("âš ï¸  æœªèƒ½è§£æåˆ°å¤šè¯­è¨€ README å†…å®¹")
        
        return ParsedReadme(
            content=results,
            languages=found_languages,
            total_count=len(results)
        )
    
    def get_filename_for_language(self, language: str) -> str:
        """
        è·å–æŒ‡å®šè¯­è¨€å¯¹åº”çš„æ–‡ä»¶å
        
        Args:
            language: è¯­è¨€åç§°
            
        Returns:
            str: å¯¹åº”çš„æ–‡ä»¶å
        """
        return self.filename_map.get(language, f"README.{language.lower()}.md")
    
    def get_supported_languages(self) -> List[str]:
        """
        è·å–æ”¯æŒè§£æçš„è¯­è¨€åˆ—è¡¨
        
        Returns:
            List[str]: æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
        """
        return list(self.language_patterns.keys())
    
    def validate_content(self, content: str) -> bool:
        """
        éªŒè¯å†…å®¹æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„å¤šè¯­è¨€READMEæ ¼å¼
        
        Args:
            content: è¦éªŒè¯çš„å†…å®¹
            
        Returns:
            bool: æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„å¤šè¯­è¨€READMEæ ¼å¼
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«è‡³å°‘ä¸€ä¸ªè¯­è¨€æ ‡è®°
        for patterns in self.language_patterns.values():
            for pattern in patterns:
                if re.search(pattern, content, re.DOTALL):
                    return True
        return False
    
    def extract_language_sections(self, content: str) -> Dict[str, str]:
        """
        æå–æ‰€æœ‰è¯­è¨€éƒ¨åˆ†çš„å†…å®¹
        
        Args:
            content: è¦è§£æçš„å†…å®¹
            
        Returns:
            Dict[str, str]: è¯­è¨€åˆ°å†…å®¹çš„æ˜ å°„
        """
        sections = {}
        
        for lang, patterns in self.language_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, content, re.DOTALL)
                if match:
                    sections[lang] = match.group(1).strip()
                    break
        
        return sections
    
    def _map_json_key_to_language(self, json_key: str) -> Optional[str]:
        """
        å°†JSONé”®æ˜ å°„åˆ°è¯­è¨€ä»£ç 
        
        Args:
            json_key: JSONä¸­çš„é”®å
            
        Returns:
            Optional[str]: å¯¹åº”çš„è¯­è¨€ä»£ç ï¼Œå¦‚æœæ— æ³•æ˜ å°„åˆ™è¿”å›None
        """
        # JSONé”®åˆ°è¯­è¨€ä»£ç çš„æ˜ å°„
        json_key_map = {
            "English readme": "en",
            "Chinese readme": "zh", 
            "Japanese readme": "ja",
            "æ—¥æœ¬èª readme": "ja",  # æ·»åŠ æ—¥è¯­å˜ä½“
            "Korean readme": "ko",
            "French readme": "fr",
            "German readme": "de",
            "Spanish readme": "es",
            "Italian readme": "it",
            "Portuguese readme": "pt",
            "Russian readme": "ru",
            "Vietnamese readme": "vi",
            "Thai readme": "th",
            "Hindi readme": "hi",
            "Arabic readme": "ar",
            "Turkish readme": "tr",
            "Polish readme": "pl",
            "Dutch readme": "nl",
            "Swedish readme": "sv",
            "Danish readme": "da",
            "Norwegian readme": "no"
        }
        
        return json_key_map.get(json_key) 